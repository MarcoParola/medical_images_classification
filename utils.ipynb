{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "utils.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarcoParola/medical_images_classification/blob/main/utils.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EScfUT3IO-Ta"
      },
      "source": [
        "# **Utils**\r\n",
        "This notebook contains some functions used in other notebooks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jjzi0wyoNpB4"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from sklearn import metrics\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import auc"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsJPM8GZT7Ky"
      },
      "source": [
        "def load_data(dir):\n",
        "  imagesTrain = np.load(os.path.join(dir + 'train_tensor.npy'))\n",
        "  labelsTrain = np.load(os.path.join(dir + 'train_labels.npy'))\n",
        "  imagesTestPublic = np.load(os.path.join(dir + 'public_test_tensor.npy'))\n",
        "  labelsTestPublic = np.load(os.path.join(dir + 'public_test_labels.npy'))\n",
        "  imagesTestPrivate = np.load(os.path.join(dir + 'private_test_tensor.npy'))\n",
        "\n",
        "  return imagesTrain, labelsTrain, imagesTestPublic, labelsTestPublic, imagesTestPrivate"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNgA79TBIgQk"
      },
      "source": [
        "def scaleData(image):\n",
        "  scaledImage = image / (pow(2,16)-1)\n",
        "  return scaledImage"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txJWasNmPbGH"
      },
      "source": [
        "## Utility function that plots the confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6ZLc-BWoag8"
      },
      "source": [
        "def plot_confusionMatrix(model_, testSet_, testLabels_, classes):\r\n",
        "    pred = model_.predict_classes(testSet_)\r\n",
        "    cm = metrics.confusion_matrix(pred, testLabels_)\r\n",
        "    plt.imshow(cm, interpolation='nearest', cmap='OrRd')\r\n",
        "    plt.title('Confusion matrix')\r\n",
        "    plt.colorbar()\r\n",
        "    tick_marks = np.arange(len(classes))\r\n",
        "    print(tick_marks)\r\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\r\n",
        "    plt.yticks(tick_marks, classes)\r\n",
        "\r\n",
        "    cm = np.round( cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] ,2)\r\n",
        "    print(\"Normalized confusion matrix\")\r\n",
        "    thresh = 0.6\r\n",
        "    \r\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\r\n",
        "        plt.text(j, i, cm[i, j],horizontalalignment=\"center\",color=\"white\" if cm[i, j] > thresh else \"black\")\r\n",
        "\r\n",
        "    plt.tight_layout()\r\n",
        "    plt.ylabel('True label')\r\n",
        "    plt.xlabel('Predicted label')\r\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxzaHlEiodmT"
      },
      "source": [
        "## Utility function that plots roc curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWKe8MnA3W9k"
      },
      "source": [
        "def plotRocCurves(models, test, labels):\r\n",
        "  for i in range(len(models)):\r\n",
        "    probs = models[i].predict_proba(test)\r\n",
        "    preds = probs[:,1]\r\n",
        "    fpr, tpr, threshold = metrics.roc_curve(labels, preds)\r\n",
        "    roc_auc = metrics.auc(fpr, tpr)\r\n",
        "\r\n",
        "    # method I: plt\r\n",
        "    import matplotlib.pyplot as plt\r\n",
        "    plt.title('Confusion matrix')\r\n",
        "    plt.plot(fpr, tpr, 'b', color=(np.random.rand(),np.random.rand(),np.random.rand()), label = 'model' + str(i+1) + '= %0.2f' % roc_auc)\r\n",
        "    plt.legend(loc = 'lower right')\r\n",
        "    plt.plot([0, 1], [0, 1],'r--')\r\n",
        "    plt.xlim([0, 1])\r\n",
        "    plt.ylim([0, 1])\r\n",
        "    plt.ylabel('True Positive Rate')\r\n",
        "    plt.xlabel('False Positive Rate')\r\n",
        "  plt.show()"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDe_CYrj3e5l"
      },
      "source": [
        "def plot_accurancy_loss(hist):\r\n",
        "  acc_1 = hist.history['accuracy']\r\n",
        "  val_acc_1 = hist.history['val_accuracy']\r\n",
        "  loss_1 = hist.history['loss']\r\n",
        "  val_loss_1 = hist.history['val_loss']\r\n",
        "\r\n",
        "  plt.ylim(0,1)\r\n",
        "  \r\n",
        "  epochs = range(len(acc_1))\r\n",
        "\r\n",
        "  plt.plot(epochs, acc_1, 'bo', label='Training acc')\r\n",
        "  plt.plot(epochs, val_acc_1, 'b', label='Validation acc')\r\n",
        "  plt.title('Training and validation accuracy')\r\n",
        "  plt.legend()\r\n",
        "\r\n",
        "  plt.figure()\r\n",
        "  plt.ylim(0,1)\r\n",
        "  plt.plot(epochs, loss_1, 'bo', label='Training loss')\r\n",
        "  plt.plot(epochs, val_loss_1, 'b', label='Validation loss')\r\n",
        "  plt.title('Training and validation loss')\r\n",
        "  plt.legend()\r\n",
        "\r\n",
        "  plt.show()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kR0SYxyRk2JA"
      },
      "source": [
        "def plot_roc_curve(model1, model1_name, model2, model2_name, set_):\r\n",
        "  y_pred_1 = model1.predict_classes(set_)#.ravel()\r\n",
        "  fpr_1, tpr_1, thresholds_1 = roc_curve(set_, y_pred_1)\r\n",
        "  auc_1 = auc(fpr_1, tpr_1)\r\n",
        "  '''\r\n",
        "  y_pred_2 = model2.predict_classes(set_)#.ravel()\r\n",
        "  fpr_2, tpr_2, thresholds_2 = roc_curve(set_, y_pred_2)\r\n",
        "  auc_2 = auc(fpr_2, tpr_2)\r\n",
        "  '''\r\n",
        "  plt.figure(1)\r\n",
        "  plt.plot([0, 1], [0, 1], 'k--')\r\n",
        "  plt.plot(fpr_1, tpr_1, label='model1_name (area = {:.3f})'.format(auc_1)) #rivedere nomi modelli da stampare\r\n",
        "  #plt.plot(fpr_2, tpr_2, label='model2_name (area = {:.3f})'.format(auc_2))\r\n",
        "  plt.xlabel('False positive rate')\r\n",
        "  plt.ylabel('True positive rate')\r\n",
        "  plt.title('ROC curve')\r\n",
        "  plt.legend(loc='best')\r\n",
        "  plt.show()\r\n",
        "  '''\r\n",
        "  plt.figure(1)\r\n",
        "  plt.plot([0, 1], [0, 1], 'k--')\r\n",
        "  plt.plot(fpr_keras, tpr_keras, label='Keras (area = {:.3f})'.format(auc_keras))\r\n",
        "  plt.plot(fpr_rf, tpr_rf, label='RF (area = {:.3f})'.format(auc_rf))\r\n",
        "  plt.xlabel('False positive rate')\r\n",
        "  plt.ylabel('True positive rate')\r\n",
        "  plt.title('ROC curve')\r\n",
        "  plt.legend(loc='best')\r\n",
        "  plt.show()\r\n",
        "  '''"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9mVhk_auhBD"
      },
      "source": [
        "def plot_roc_curve1(model1, model1_name, model2, model2_name, set_):\r\n",
        "  # Plot linewidth.\r\n",
        "  lw = 2\r\n",
        "\r\n",
        "  # Compute ROC curve and ROC area for each class\r\n",
        "  fpr = dict()\r\n",
        "  tpr = dict()\r\n",
        "  roc_auc = dict()\r\n",
        "  for i in range(n_classes):\r\n",
        "      fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\r\n",
        "      roc_auc[i] = auc(fpr[i], tpr[i])\r\n",
        "\r\n",
        "  # Compute micro-average ROC curve and ROC area\r\n",
        "  fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\r\n",
        "  roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\r\n",
        "\r\n",
        "  # Compute macro-average ROC curve and ROC area\r\n",
        "\r\n",
        "  # First aggregate all false positive rates\r\n",
        "  all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\r\n",
        "\r\n",
        "  # Then interpolate all ROC curves at this points\r\n",
        "  mean_tpr = np.zeros_like(all_fpr)\r\n",
        "  for i in range(n_classes):\r\n",
        "      mean_tpr += interp(all_fpr, fpr[i], tpr[i])\r\n",
        "\r\n",
        "  # Finally average it and compute AUC\r\n",
        "  mean_tpr /= n_classes\r\n",
        "\r\n",
        "  fpr[\"macro\"] = all_fpr\r\n",
        "  tpr[\"macro\"] = mean_tpr\r\n",
        "  roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\r\n",
        "\r\n",
        "  # Plot all ROC curves\r\n",
        "  plt.figure(1)\r\n",
        "  plt.plot(fpr[\"micro\"], tpr[\"micro\"],\r\n",
        "          label='micro-average ROC curve (area = {0:0.2f})'\r\n",
        "                ''.format(roc_auc[\"micro\"]),\r\n",
        "          color='deeppink', linestyle=':', linewidth=4)\r\n",
        "\r\n",
        "  plt.plot(fpr[\"macro\"], tpr[\"macro\"],\r\n",
        "          label='macro-average ROC curve (area = {0:0.2f})'\r\n",
        "                ''.format(roc_auc[\"macro\"]),\r\n",
        "          color='navy', linestyle=':', linewidth=4)\r\n",
        "\r\n",
        "  colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\r\n",
        "  for i, color in zip(range(n_classes), colors):\r\n",
        "      plt.plot(fpr[i], tpr[i], color=color, lw=lw,\r\n",
        "              label='ROC curve of class {0} (area = {1:0.2f})'\r\n",
        "              ''.format(i, roc_auc[i]))\r\n",
        "\r\n",
        "  plt.plot([0, 1], [0, 1], 'k--', lw=lw)\r\n",
        "  plt.xlim([0.0, 1.0])\r\n",
        "  plt.ylim([0.0, 1.05])\r\n",
        "  plt.xlabel('False Positive Rate')\r\n",
        "  plt.ylabel('True Positive Rate')\r\n",
        "  plt.title('Some extension of Receiver operating characteristic to multi-class')\r\n",
        "  plt.legend(loc=\"lower right\")\r\n",
        "  plt.show()"
      ],
      "execution_count": 31,
      "outputs": []
    }
  ]
}